{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Pipeline Model Deployment</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have built and trained our models for feature engineering (using Amazon SageMaker Processing and SKLearn) and binary classification (using the XGBoost open-source container for Amazon SageMaker), we can choose to deploy them in a pipeline on Amazon SageMaker Hosting, by creating an Inference Pipeline.\n",
    "https://docs.aws.amazon.com/sagemaker/latest/dg/inference-pipelines.html\n",
    "\n",
    "This notebook demonstrates how to create a pipeline with the SKLearn model for feature engineering and the XGBoost model for binary classification.\n",
    "\n",
    "Let's define the variables first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eu-west-1\n",
      "arn:aws:iam::825935527263:role/service-role/AmazonSageMaker-ExecutionRole-endtoendml\n",
      "sagemaker-eu-west-1-825935527263\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "region = boto3.Session().region_name\n",
    "sagemaker_session = sagemaker.Session()\n",
    "bucket_name = sagemaker_session.default_bucket()\n",
    "prefix = 'endtoendmlsm'\n",
    "\n",
    "print(region)\n",
    "print(role)\n",
    "print(bucket_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to create two Amazon SageMaker **Model** objects, which associate the artifacts of training (serialized model artifacts in Amazon S3) to the Docker container used for inference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to do that, we need to get the paths to our serialized models in Amazon S3.\n",
    "<ul>\n",
    "    <li>For the SKLearn model, in Step 02 (data exploration and feature engineering) we defined the path where the artifacts are saved</li>\n",
    "    <li>For the XGBoost model, we need to find the path based on Amazon SageMaker's naming convention</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SKLearn model path: s3://sagemaker-eu-west-1-825935527263/endtoendmlsm/output/sklearn/model.tar.gz\n",
      "XGBoost model path: s3://sagemaker-eu-west-1-825935527263/endtoendmlsm/output/end-to-end-ml-sm-xgb-2020-03-26-15-21-27-536/output/model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "from notebook_utilities import get_latest_training_job_name, get_training_job_s3_model_artifacts\n",
    "\n",
    "# SKLearn model path.\n",
    "sklearn_model_path = 's3://{0}/{1}/output/sklearn/model.tar.gz'.format(bucket_name, prefix)\n",
    "\n",
    "training_base_job_name = 'end-to-end-ml-sm-xgb'\n",
    "latest_training_job_name = get_latest_training_job_name(training_base_job_name)\n",
    "# XGBoost model path.\n",
    "xgboost_model_path = get_training_job_s3_model_artifacts(latest_training_job_name)\n",
    "\n",
    "print('SKLearn model path: ' + sklearn_model_path)\n",
    "print('XGBoost model path: ' + xgboost_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SKLearn Featurizer Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's build the SKLearn model. For hosting this model we also provide a custom inference script, that is used to process the inputs and outputs and execute the transform.\n",
    "\n",
    "The inference script is implemented in the `sklearn_source_dir/inference.py` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36m__future__\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m print_function\n",
      "\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36msys\u001b[39;49;00m\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mio\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m StringIO\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mos\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mcsv\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mjson\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mnumpy\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mnp\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mpandas\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mpd\u001b[39;49;00m\n",
      "\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36msklearn.externals\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m joblib\n",
      "\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36msagemaker_containers.beta.framework\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m (\n",
      "    content_types, encoders, env, modules, transformer, worker)\n",
      "\n",
      "feature_columns_names = [\u001b[33m'\u001b[39;49;00m\u001b[33mturbine_id\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mturbine_type\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mwind_speed\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mrpm_blade\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33moil_temperature\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n",
      "                         \u001b[33m'\u001b[39;49;00m\u001b[33moil_level\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mtemperature\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mhumidity\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mvibrations_frequency\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mpressure\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mwind_direction\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32minput_fn\u001b[39;49;00m(input_data, content_type):\n",
      "    \u001b[34mprint\u001b[39;49;00m(input_data)\n",
      "    \n",
      "    \u001b[34mif\u001b[39;49;00m content_type == \u001b[33m'\u001b[39;49;00m\u001b[33mtext/csv\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "        df = pd.read_csv(StringIO(input_data), header=\u001b[36mNone\u001b[39;49;00m)\n",
      "        \u001b[34mif\u001b[39;49;00m \u001b[36mlen\u001b[39;49;00m(df.columns) == \u001b[36mlen\u001b[39;49;00m(feature_columns_names):\n",
      "            df.columns = feature_columns_names \n",
      "        \u001b[34mreturn\u001b[39;49;00m df\n",
      "    \u001b[34melse\u001b[39;49;00m:\n",
      "        \u001b[34mraise\u001b[39;49;00m \u001b[36mValueError\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33m{} not supported by script!\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m.format(content_type))\n",
      "        \n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mpredict_fn\u001b[39;49;00m(input_data, model):\n",
      "    features = model.transform(input_data)\n",
      "    \u001b[34mreturn\u001b[39;49;00m features\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32moutput_fn\u001b[39;49;00m(prediction, accept):\n",
      "    \u001b[34mif\u001b[39;49;00m accept == \u001b[33m\"\u001b[39;49;00m\u001b[33mapplication/json\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\n",
      "        instances = []\n",
      "        \u001b[34mfor\u001b[39;49;00m row \u001b[35min\u001b[39;49;00m prediction.tolist():\n",
      "            instances.append({\u001b[33m\"\u001b[39;49;00m\u001b[33mfeatures\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: row})\n",
      "        json_output = {\u001b[33m\"\u001b[39;49;00m\u001b[33minstances\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m: instances}\n",
      "\n",
      "        \u001b[34mreturn\u001b[39;49;00m worker.Response(json.dumps(json_output), mimetype=accept)\n",
      "    \u001b[34melif\u001b[39;49;00m accept == \u001b[33m'\u001b[39;49;00m\u001b[33mtext/csv\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "        \u001b[34mreturn\u001b[39;49;00m worker.Response(encoders.encode(prediction, accept), mimetype=accept)\n",
      "    \u001b[34melse\u001b[39;49;00m:\n",
      "        \u001b[34mraise\u001b[39;49;00m RuntimeException(\u001b[33m\"\u001b[39;49;00m\u001b[33m{} accept type is not supported by this script.\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m.format(accept))\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mmodel_fn\u001b[39;49;00m(model_dir):\n",
      "    preprocessor = joblib.load(os.path.join(model_dir, \u001b[33m\"\u001b[39;49;00m\u001b[33mopt/ml/processing/model/model.joblib\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m))\n",
      "    \u001b[34mreturn\u001b[39;49;00m preprocessor\n"
     ]
    }
   ],
   "source": [
    "!pygmentize sklearn_source_dir/inference.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from sagemaker.sklearn import SKLearnModel\n",
    "\n",
    "code_location = 's3://{0}/{1}/code'.format(bucket_name, prefix)\n",
    "\n",
    "sklearn_model = SKLearnModel(name='end-to-end-ml-sm-skl-model-{0}'.format(str(int(time.time()))),\n",
    "                             model_data=sklearn_model_path,\n",
    "                             entry_point='inference.py',\n",
    "                             source_dir='sklearn_source_dir/',\n",
    "                             code_location=code_location,\n",
    "                             role=role,\n",
    "                             sagemaker_session=sagemaker_session\n",
    "                             )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mos\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mpickle\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mpkl\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mjson\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mnumpy\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mnp\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mxgboost\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mxgb\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mpandas\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mpd\u001b[39;49;00m\n",
      "\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36msagemaker_containers.beta.framework\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m (\n",
      "    content_types, encoders, env, modules, transformer, worker)\n",
      "\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36msagemaker_xgboost_container\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m encoder \u001b[34mas\u001b[39;49;00m xgb_encoders\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32minput_fn\u001b[39;49;00m(input_data, content_type):\n",
      "    \u001b[34mprint\u001b[39;49;00m(\u001b[33m'\u001b[39;49;00m\u001b[33mPrinting inputs.\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "    \u001b[34mprint\u001b[39;49;00m(content_type)\n",
      "    \u001b[34mprint\u001b[39;49;00m(input_data)\n",
      "    \n",
      "    \u001b[34mif\u001b[39;49;00m content_type == content_types.JSON:\n",
      "        obj = json.loads(input_data)\n",
      "        features = obj[\u001b[33m'\u001b[39;49;00m\u001b[33minstances\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m][\u001b[34m0\u001b[39;49;00m][\u001b[33m'\u001b[39;49;00m\u001b[33mfeatures\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]\n",
      "        array = np.array(features).reshape((\u001b[34m1\u001b[39;49;00m, -\u001b[34m1\u001b[39;49;00m))\n",
      "        \u001b[34mreturn\u001b[39;49;00m xgb.DMatrix(array)\n",
      "    \u001b[34melse\u001b[39;49;00m:\n",
      "        \u001b[34mreturn\u001b[39;49;00m xgb_encoders.decode(input_data, content_type)\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mmodel_fn\u001b[39;49;00m(model_dir):\n",
      "    model_file = model_dir + \u001b[33m'\u001b[39;49;00m\u001b[33m/model.bin\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\n",
      "    model = pkl.load(\u001b[36mopen\u001b[39;49;00m(model_file, \u001b[33m'\u001b[39;49;00m\u001b[33mrb\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m))\n",
      "    \u001b[34mreturn\u001b[39;49;00m model\n"
     ]
    }
   ],
   "source": [
    "!pygmentize xgboost_source_dir/inference.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from sagemaker.xgboost import XGBoostModel\n",
    "\n",
    "code_location = 's3://{0}/{1}/code'.format(bucket_name, prefix)\n",
    "\n",
    "xgboost_model = XGBoostModel(name='end-to-end-ml-sm-xgb-model-{0}'.format(str(int(time.time()))),\n",
    "                             model_data=xgboost_model_path,\n",
    "                             entry_point='inference.py',\n",
    "                             source_dir='xgboost_source_dir/',\n",
    "                             code_location=code_location,\n",
    "                             framework_version='0.90-2',\n",
    "                             role=role, \n",
    "                             sagemaker_session=sagemaker_session\n",
    "                             )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have models ready, we can deploy them in a pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end-to-end-ml-sm-pipeline-endpoint-1585316383\n",
      "-------------!"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "import time\n",
    "from sagemaker.pipeline import PipelineModel\n",
    "\n",
    "pipeline_model_name = 'end-to-end-ml-sm-xgb-skl-pipeline-{0}'.format(str(int(time.time())))\n",
    "\n",
    "pipeline_model = PipelineModel(\n",
    "    name=pipeline_model_name, \n",
    "    role=role,\n",
    "    models=[\n",
    "        sklearn_model, \n",
    "        xgboost_model],\n",
    "    sagemaker_session=sagemaker_session)\n",
    "\n",
    "endpoint_name = 'end-to-end-ml-sm-pipeline-endpoint-{0}'.format(str(int(time.time())))\n",
    "print(endpoint_name)\n",
    "\n",
    "pipeline_model.deploy(initial_instance_count=1, \n",
    "                      instance_type='ml.c5.xlarge', \n",
    "                      endpoint_name=endpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: red; font-weight:bold\">Please take note of the endpoint name, since it will be used in the next workshop module.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Getting inferences</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can try invoking our pipeline of models and try getting some inferences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6588892936706543]\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.predictor import json_serializer, csv_serializer, csv_deserializer, json_deserializer, RealTimePredictor\n",
    "from sagemaker.content_types import CONTENT_TYPE_CSV, CONTENT_TYPE_JSON\n",
    "\n",
    "predictor = RealTimePredictor(\n",
    "    endpoint=endpoint_name,\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    content_type=CONTENT_TYPE_CSV,\n",
    "    accept=CONTENT_TYPE_JSON)\n",
    "\n",
    "predictor.serializer = csv_serializer\n",
    "predictor.deserializer = json_deserializer\n",
    "\n",
    "payload = \"TID008,HAWT,64,80,46,21,55,55,7,34,SE\"\n",
    "print(predictor.predict(payload))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have tested the endpoint, we can move to the next workshop module. Please access the module <a href=\"https://github.com/giuseppeporcelli/end-to-end-ml-application/tree/master/05_API_Gateway_and_Lambda\" target=\"_blank\">05_API_Gateway_and_Lambda</a> on GitHub to continue."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
